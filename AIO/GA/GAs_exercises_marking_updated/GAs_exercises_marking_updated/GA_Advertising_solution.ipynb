{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import các libraries cần thiết và load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aivietnam.ai - advertising\n",
    "import numpy as np\n",
    "# from numpy import genfromtxt\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "random.seed(0) # please do not remove this line\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 4) (200,)\n",
      "[22.1 10.4 12.  16.5 17.9  7.2 11.8 13.2  4.8 15.6 12.6 17.4  9.2 13.7\n",
      " 19.  22.4 12.5 24.4 11.3 14.6 18.  17.5  5.6 20.5  9.7 17.  15.  20.9\n",
      " 18.9 10.5 21.4 11.9 13.2 17.4 11.9 17.8 25.4 14.7 10.1 21.5 16.6 17.1\n",
      " 20.7 17.9  8.5 16.1 10.6 23.2 19.8  9.7 16.4 10.7 22.6 21.2 20.2 23.7\n",
      "  5.5 13.2 23.8 18.4  8.1 24.2 20.7 14.  16.  11.3 11.  13.4 18.9 22.3\n",
      " 18.3 12.4  8.8 11.  17.   8.7  6.9 14.2  5.3 11.  11.8 17.3 11.3 13.6\n",
      " 21.7 20.2 12.  16.  12.9 16.7 14.   7.3 19.4 22.2 11.5 16.9 16.7 20.5\n",
      " 25.4 17.2 16.7 23.8 19.8 19.7 20.7 15.   7.2 12.   5.3 19.8 18.4 21.8\n",
      " 17.1 20.9 14.6 12.6 12.2  9.4 15.9  6.6 15.5  7.  16.6 15.2 19.7 10.6\n",
      "  6.6 11.9 24.7  9.7  1.6 17.7  5.7 19.6 10.8 11.6  9.5 20.8  9.6 20.7\n",
      " 10.9 19.2 20.1 10.4 12.3 10.3 18.2 25.4 10.9 10.1 16.1 11.6 16.6 16.\n",
      " 20.6  3.2 15.3 10.1  7.3 12.9 16.4 13.3 19.9 18.  11.9 16.9  8.  17.2\n",
      " 17.1 20.   8.4 17.5  7.6 16.7 16.5 27.  20.2 16.7 16.8 17.6 15.5 17.2\n",
      "  8.7 26.2 17.6 22.6 10.3 17.3 20.9  6.7 10.8 11.9  5.9 19.6 17.3  7.6\n",
      " 14.  14.8 25.5 18.4]\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt('advertising.csv', \n",
    "                     dtype=None, \n",
    "                     delimiter=',', \n",
    "                     skip_header=1) \n",
    "features = data[:, :3]\n",
    "prices = data[:, 3]\n",
    "\n",
    "intercept = np.ones((features.shape[0], 1))\n",
    "features = np.concatenate((intercept, features), axis=1)\n",
    "\n",
    "print(features.shape, prices.shape)\n",
    "print(prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huấn luyện và nhận định"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4                  # size of individual (chromosome); 3 coefficients and 1 bias\n",
    "m = 600                # size of population\n",
    "n_generations = 100   # number of generations\n",
    "losses = []            # để vẽ biểu đồ quá trình tối ưu\n",
    "individuals = []       # chứa các tham số trong quá trình training (theta)\n",
    "\n",
    "def generate_random_value(bound = 10):\n",
    "    return (random.random() - 0.5)*bound\n",
    "\n",
    "def compute_loss(individual):\n",
    "    \n",
    "    theta = np.array(individual)    \n",
    "    y_hat = features.dot(theta)\n",
    "    loss  = np.multiply((y_hat-prices), (y_hat-prices)).mean()\n",
    "    return loss\n",
    "\n",
    "\n",
    "def compute_fitness(individual):\n",
    "    loss = compute_loss(individual)\n",
    "    fitness = 1 / (loss + 1)\n",
    "    return fitness\n",
    "\n",
    "def create_individual():\n",
    "    return [generate_random_value() for _ in range(n)]\n",
    "\n",
    "def crossover(individual1, individual2, crossover_rate = 0.9):\n",
    "    individual1_new = individual1.copy()\n",
    "    individual2_new = individual2.copy()\n",
    "    \n",
    "    for i in range(n):\n",
    "        if random.random() < crossover_rate:\n",
    "            individual1_new[i] = individual2[i]\n",
    "            individual2_new[i] = individual1[i]            \n",
    "    \n",
    "    return individual1_new, individual2_new\n",
    "\n",
    "def mutate(individual, mutation_rate = 0.05):\n",
    "    individual_m = individual.copy()\n",
    "    \n",
    "    for i in range(n):\n",
    "        if random.random() < mutation_rate:\n",
    "            individual_m[i] = generate_random_value()\n",
    "        \n",
    "    return individual_m\n",
    "\n",
    "def selection(sorted_old_population):    \n",
    "    index1 = random.randint(0, m-1)    \n",
    "    while True:\n",
    "        index2 = random.randint(0, m-1)    \n",
    "        if (index2 != index1):\n",
    "            break\n",
    "            \n",
    "    individual_s = sorted_old_population[index1]\n",
    "    if index2 > index1:\n",
    "        individual_s = sorted_old_population[index2]\n",
    "    \n",
    "    return individual_s \n",
    "\n",
    "def create_new_population(old_population, elitism=2, gen=1):\n",
    "    sorted_population = sorted(old_population, key=compute_fitness)\n",
    "        \n",
    "    if gen%1 == 0:\n",
    "        losses.append(compute_loss(sorted_population[m-1]))\n",
    "        print(\"Best loss:\", compute_loss(sorted_population[m-1]), sorted_population[m-1])\n",
    "    \n",
    "    new_population = []\n",
    "    while len(new_population) < m-elitism:\n",
    "        # selection\n",
    "        individual_s1 = selection(sorted_population)\n",
    "        individual_s2 = selection(sorted_population) # duplication\n",
    "        \n",
    "        # crossover\n",
    "        individual_c1, individual_c2 = crossover(individual_s1, individual_s2)\n",
    "        \n",
    "        # mutation\n",
    "        individual_m1 = mutate(individual_c1)\n",
    "        individual_m2 = mutate(individual_c2)\n",
    "        \n",
    "        new_population.append(individual_m1)\n",
    "        new_population.append(individual_m2)            \n",
    "    \n",
    "    for ind in sorted_population[m-elitism:]:\n",
    "        new_population.append(ind.copy())\n",
    "    \n",
    "    return new_population\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss: 499.42870543645824 [3.331600837968306, -0.09720038244186435, 1.449875562942834, -0.2732124726990648]\n",
      "Best loss: 64.6726318959922 [1.756290748662368, 0.022221826851781534, -0.13321941847678542, 0.32743718961929735]\n",
      "Best loss: 64.6726318959922 [1.756290748662368, 0.022221826851781534, -0.13321941847678542, 0.32743718961929735]\n",
      "Best loss: 64.6726318959922 [1.756290748662368, 0.022221826851781534, -0.13321941847678542, 0.32743718961929735]\n",
      "Best loss: 64.6726318959922 [1.756290748662368, 0.022221826851781534, -0.13321941847678542, 0.32743718961929735]\n",
      "Best loss: 55.69404069589749 [-4.110466087613891, 0.03391352127992131, 0.5878075538667571, -0.05301059713686884]\n",
      "Best loss: 54.963713550426604 [4.222958711291984, 0.022221826851781534, -0.13321941847678542, 0.32743718961929735]\n",
      "Best loss: 36.639004618158566 [-4.175532773062014, 0.03923197330006567, 0.20225858991120949, 0.16124298167449536]\n",
      "Best loss: 36.639004618158566 [-4.175532773062014, 0.03923197330006567, 0.20225858991120949, 0.16124298167449536]\n",
      "Best loss: 24.948484629254654 [-4.175532773062014, 0.07302762080599101, 0.20225858991120949, 0.16124298167449536]\n",
      "Best loss: 20.126278188912753 [4.903864653534406, 0.022221826851781534, 0.3321802263059992, -0.05301059713686884]\n",
      "Best loss: 16.390148500890387 [0.1900372870132927, 0.03923197330006567, 0.20225858991120949, 0.12640705874219949]\n",
      "Best loss: 16.390148500890387 [0.1900372870132927, 0.03923197330006567, 0.20225858991120949, 0.12640705874219949]\n",
      "Best loss: 11.118818369699586 [4.903864653534406, 0.03391352127992131, 0.2710509095407232, -0.05301059713686884]\n",
      "Best loss: 11.118818369699586 [4.903864653534406, 0.03391352127992131, 0.2710509095407232, -0.05301059713686884]\n",
      "Best loss: 9.531301522856966 [4.903864653534406, 0.03923197330006567, 0.2710509095407232, -0.05301059713686884]\n",
      "Best loss: 9.531301522856966 [4.903864653534406, 0.03923197330006567, 0.2710509095407232, -0.05301059713686884]\n",
      "Best loss: 9.531301522856966 [4.903864653534406, 0.03923197330006567, 0.2710509095407232, -0.05301059713686884]\n",
      "Best loss: 9.531301522856966 [4.903864653534406, 0.03923197330006567, 0.2710509095407232, -0.05301059713686884]\n",
      "Best loss: 9.531301522856966 [4.903864653534406, 0.03923197330006567, 0.2710509095407232, -0.05301059713686884]\n",
      "Best loss: 8.431461714777054 [4.903864653534406, 0.03923197330006567, 0.20225858991120949, -0.05301059713686884]\n",
      "Best loss: 7.653012540792264 [1.756290748662368, 0.07302762080599101, 0.20225858991120949, -0.05301059713686884]\n",
      "Best loss: 7.653012540792264 [1.756290748662368, 0.07302762080599101, 0.20225858991120949, -0.05301059713686884]\n",
      "Best loss: 7.653012540792264 [1.756290748662368, 0.07302762080599101, 0.20225858991120949, -0.05301059713686884]\n",
      "Best loss: 7.653012540792264 [1.756290748662368, 0.07302762080599101, 0.20225858991120949, -0.05301059713686884]\n",
      "Best loss: 7.653012540792264 [1.756290748662368, 0.07302762080599101, 0.20225858991120949, -0.05301059713686884]\n",
      "Best loss: 7.180958941517344 [4.903864653534406, 0.03923197330006567, 0.20225858991120949, -0.04021410780180257]\n",
      "Best loss: 7.180958941517344 [4.903864653534406, 0.03923197330006567, 0.20225858991120949, -0.04021410780180257]\n",
      "Best loss: 7.180958941517344 [4.903864653534406, 0.03923197330006567, 0.20225858991120949, -0.04021410780180257]\n",
      "Best loss: 7.180958941517344 [4.903864653534406, 0.03923197330006567, 0.20225858991120949, -0.04021410780180257]\n",
      "Best loss: 7.180958941517344 [4.903864653534406, 0.03923197330006567, 0.20225858991120949, -0.04021410780180257]\n",
      "Best loss: 7.180958941517344 [4.903864653534406, 0.03923197330006567, 0.20225858991120949, -0.04021410780180257]\n",
      "Best loss: 7.180958941517344 [4.903864653534406, 0.03923197330006567, 0.20225858991120949, -0.04021410780180257]\n",
      "Best loss: 7.180958941517344 [4.903864653534406, 0.03923197330006567, 0.20225858991120949, -0.04021410780180257]\n",
      "Best loss: 7.180958941517344 [4.903864653534406, 0.03923197330006567, 0.20225858991120949, -0.04021410780180257]\n",
      "Best loss: 6.918359885800272 [1.756290748662368, 0.07302762080599101, 0.1513835281259257, -0.05301059713686884]\n",
      "Best loss: 6.918359885800272 [1.756290748662368, 0.07302762080599101, 0.1513835281259257, -0.05301059713686884]\n",
      "Best loss: 6.839372533259572 [4.081681544074826, 0.044410052412586776, 0.20225858991120949, -0.0454525038971032]\n",
      "Best loss: 6.109780194016866 [1.756290748662368, 0.07302762080599101, 0.1513835281259257, -0.04021410780180257]\n",
      "Best loss: 5.538722038941184 [4.903864653534406, 0.044410052412586776, 0.20225858991120949, -0.0454525038971032]\n",
      "Best loss: 5.331906860153406 [4.903864653534406, 0.044410052412586776, 0.20225858991120949, -0.04021410780180257]\n",
      "Best loss: 5.331906860153406 [4.903864653534406, 0.044410052412586776, 0.20225858991120949, -0.04021410780180257]\n",
      "Best loss: 5.331906860153406 [4.903864653534406, 0.044410052412586776, 0.20225858991120949, -0.04021410780180257]\n",
      "Best loss: 5.331906860153406 [4.903864653534406, 0.044410052412586776, 0.20225858991120949, -0.04021410780180257]\n",
      "Best loss: 5.331906860153406 [4.903864653534406, 0.044410052412586776, 0.20225858991120949, -0.04021410780180257]\n",
      "Best loss: 5.331906860153406 [4.903864653534406, 0.044410052412586776, 0.20225858991120949, -0.04021410780180257]\n",
      "Best loss: 5.305114570854877 [4.9769544727077175, 0.044410052412586776, 0.20225858991120949, -0.04021410780180257]\n",
      "Best loss: 5.299836689417188 [4.9962006103448235, 0.044410052412586776, 0.20225858991120949, -0.04021410780180257]\n",
      "Best loss: 5.299836689417188 [4.9962006103448235, 0.044410052412586776, 0.20225858991120949, -0.04021410780180257]\n",
      "Best loss: 5.299836689417188 [4.9962006103448235, 0.044410052412586776, 0.20225858991120949, -0.04021410780180257]\n",
      "Best loss: 5.299836689417188 [4.9962006103448235, 0.044410052412586776, 0.20225858991120949, -0.04021410780180257]\n",
      "Best loss: 5.299836689417188 [4.9962006103448235, 0.044410052412586776, 0.20225858991120949, -0.04021410780180257]\n",
      "Best loss: 5.160285148697808 [4.903864653534406, 0.044410052412586776, 0.20225858991120949, -0.025882045120267927]\n",
      "Best loss: 5.160285148697808 [4.903864653534406, 0.044410052412586776, 0.20225858991120949, -0.025882045120267927]\n",
      "Best loss: 5.160285148697808 [4.903864653534406, 0.044410052412586776, 0.20225858991120949, -0.025882045120267927]\n",
      "Best loss: 5.160285148697808 [4.903864653534406, 0.044410052412586776, 0.20225858991120949, -0.025882045120267927]\n",
      "Best loss: 5.160285148697808 [4.903864653534406, 0.044410052412586776, 0.20225858991120949, -0.025882045120267927]\n",
      "Best loss: 4.982355688857598 [4.903864653534406, 0.044410052412586776, 0.14797528795292725, -0.025882045120267927]\n",
      "Best loss: 4.982355688857598 [4.903864653534406, 0.044410052412586776, 0.14797528795292725, -0.025882045120267927]\n",
      "Best loss: 4.982355688857598 [4.903864653534406, 0.044410052412586776, 0.14797528795292725, -0.025882045120267927]\n",
      "Best loss: 4.797941365991141 [4.9962006103448235, 0.044410052412586776, 0.14797528795292725, -0.025882045120267927]\n",
      "Best loss: 4.797941365991141 [4.9962006103448235, 0.044410052412586776, 0.14797528795292725, -0.025882045120267927]\n",
      "Best loss: 4.797941365991141 [4.9962006103448235, 0.044410052412586776, 0.14797528795292725, -0.025882045120267927]\n",
      "Best loss: 4.797941365991141 [4.9962006103448235, 0.044410052412586776, 0.14797528795292725, -0.025882045120267927]\n",
      "Best loss: 4.797941365991141 [4.9962006103448235, 0.044410052412586776, 0.14797528795292725, -0.025882045120267927]\n",
      "Best loss: 4.5083276847920795 [4.903864653534406, 0.044410052412586776, 0.17399073660510522, -0.025882045120267927]\n",
      "Best loss: 4.5083276847920795 [4.903864653534406, 0.044410052412586776, 0.17399073660510522, -0.025882045120267927]\n",
      "Best loss: 4.5083276847920795 [4.903864653534406, 0.044410052412586776, 0.17399073660510522, -0.025882045120267927]\n",
      "Best loss: 4.5083276847920795 [4.903864653534406, 0.044410052412586776, 0.17399073660510522, -0.025882045120267927]\n",
      "Best loss: 4.435681124899761 [4.9962006103448235, 0.044410052412586776, 0.17399073660510522, -0.025882045120267927]\n",
      "Best loss: 4.435681124899761 [4.9962006103448235, 0.044410052412586776, 0.17399073660510522, -0.025882045120267927]\n",
      "Best loss: 4.435681124899761 [4.9962006103448235, 0.044410052412586776, 0.17399073660510522, -0.025882045120267927]\n",
      "Best loss: 4.435681124899761 [4.9962006103448235, 0.044410052412586776, 0.17399073660510522, -0.025882045120267927]\n",
      "Best loss: 4.435681124899761 [4.9962006103448235, 0.044410052412586776, 0.17399073660510522, -0.025882045120267927]\n",
      "Best loss: 4.435681124899761 [4.9962006103448235, 0.044410052412586776, 0.17399073660510522, -0.025882045120267927]\n",
      "Best loss: 4.435681124899761 [4.9962006103448235, 0.044410052412586776, 0.17399073660510522, -0.025882045120267927]\n",
      "Best loss: 4.435681124899761 [4.9962006103448235, 0.044410052412586776, 0.17399073660510522, -0.025882045120267927]\n",
      "Best loss: 4.435681124899761 [4.9962006103448235, 0.044410052412586776, 0.17399073660510522, -0.025882045120267927]\n",
      "Best loss: 4.435681124899761 [4.9962006103448235, 0.044410052412586776, 0.17399073660510522, -0.025882045120267927]\n",
      "Best loss: 4.435681124899761 [4.9962006103448235, 0.044410052412586776, 0.17399073660510522, -0.025882045120267927]\n",
      "Best loss: 4.435681124899761 [4.9962006103448235, 0.044410052412586776, 0.17399073660510522, -0.025882045120267927]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss: 4.435681124899761 [4.9962006103448235, 0.044410052412586776, 0.17399073660510522, -0.025882045120267927]\n",
      "Best loss: 4.435681124899761 [4.9962006103448235, 0.044410052412586776, 0.17399073660510522, -0.025882045120267927]\n",
      "Best loss: 4.435681124899761 [4.9962006103448235, 0.044410052412586776, 0.17399073660510522, -0.025882045120267927]\n",
      "Best loss: 4.390831152332856 [4.9962006103448235, 0.044410052412586776, 0.17399073660510522, -0.02442430296732634]\n",
      "Best loss: 4.390831152332856 [4.9962006103448235, 0.044410052412586776, 0.17399073660510522, -0.02442430296732634]\n",
      "Best loss: 4.390831152332856 [4.9962006103448235, 0.044410052412586776, 0.17399073660510522, -0.02442430296732634]\n",
      "Best loss: 4.390831152332856 [4.9962006103448235, 0.044410052412586776, 0.17399073660510522, -0.02442430296732634]\n",
      "Best loss: 4.390831152332856 [4.9962006103448235, 0.044410052412586776, 0.17399073660510522, -0.02442430296732634]\n",
      "Best loss: 4.390831152332856 [4.9962006103448235, 0.044410052412586776, 0.17399073660510522, -0.02442430296732634]\n",
      "Best loss: 4.390831152332856 [4.9962006103448235, 0.044410052412586776, 0.17399073660510522, -0.02442430296732634]\n",
      "Best loss: 4.390831152332856 [4.9962006103448235, 0.044410052412586776, 0.17399073660510522, -0.02442430296732634]\n",
      "Best loss: 4.390831152332856 [4.9962006103448235, 0.044410052412586776, 0.17399073660510522, -0.02442430296732634]\n",
      "Best loss: 4.390831152332856 [4.9962006103448235, 0.044410052412586776, 0.17399073660510522, -0.02442430296732634]\n",
      "Best loss: 4.390831152332856 [4.9962006103448235, 0.044410052412586776, 0.17399073660510522, -0.02442430296732634]\n",
      "Best loss: 4.245769522498108 [4.9962006103448235, 0.044410052412586776, 0.17399073660510522, -0.013129404272822498]\n",
      "Best loss: 4.245769522498108 [4.9962006103448235, 0.044410052412586776, 0.17399073660510522, -0.013129404272822498]\n",
      "Best loss: 4.245769522498108 [4.9962006103448235, 0.044410052412586776, 0.17399073660510522, -0.013129404272822498]\n",
      "Best loss: 4.245769522498108 [4.9962006103448235, 0.044410052412586776, 0.17399073660510522, -0.013129404272822498]\n",
      "Best loss: 4.245769522498108 [4.9962006103448235, 0.044410052412586776, 0.17399073660510522, -0.013129404272822498]\n"
     ]
    }
   ],
   "source": [
    "population = [create_individual() for _ in range(m)]\n",
    "for i in range(n_generations):\n",
    "    population = create_new_population(population, 2, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best loss after 1 generation (n_generations = 1): 499.42870543645824"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best solution after 100 generations (n_generations = 100): [4.9962006103448235, 0.044410052412586776, 0.17399073660510522, -0.013129404272822498]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses[:200], c='green')\n",
    "plt.xlabel('Generations')\n",
    "plt.ylabel('losses')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization of ground truth and predict value\n",
    "sorted_population = sorted(population, key=compute_fitness)\n",
    "print(sorted_population[-1])\n",
    "theta = np.array(sorted_population[-1])\n",
    "\n",
    "estimated_prices = []\n",
    "for feature in features:        \n",
    "    estimated_price = sum(c*x for x, c in zip(feature, theta))\n",
    "    estimated_prices.append(estimated_price)\n",
    "         \n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "plt.plot(prices, c='green')    \n",
    "plt.plot(estimated_prices, c='red')\n",
    "plt.xlabel('Samples')\n",
    "plt.ylabel('Price')\n",
    "plt.plot(prices, c='green', label='Real Prices')\n",
    "plt.plot(estimated_prices, c='blue', label='Estimated Prices')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "9bc3bf6bb691733f333e01dcfce30c4108997f38332bc33fef4fedd2eeb40313"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
