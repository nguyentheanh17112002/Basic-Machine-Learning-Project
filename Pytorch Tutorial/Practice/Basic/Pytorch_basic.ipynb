{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10ee8498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c2d52c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(10.0 , requires_grad = True)\n",
    "w = torch.tensor(5.0 , requires_grad = True)\n",
    "b = torch.tensor(2.0 , requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7511dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = w*x + b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c93a1a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute gradient\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb2bf91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.)\n",
      "tensor(10.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "#compute grad\n",
    "print(x.grad)\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94c71cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "948ff02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(10 ,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49a44144",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.randn(10 , 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f85741da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6120,  0.2920,  0.6790],\n",
      "        [-0.0259,  0.9472,  0.5120],\n",
      "        [-0.8103,  0.6171, -1.2129],\n",
      "        [-0.3795,  0.9391, -0.6970],\n",
      "        [-1.3107,  0.8368, -0.2377],\n",
      "        [-0.6422,  1.0913, -0.5095],\n",
      "        [-1.9373, -0.9677,  0.0349],\n",
      "        [-0.3308,  0.7391, -0.1819],\n",
      "        [ 0.2273, -1.7210, -1.0191],\n",
      "        [ 1.1702,  0.4237, -0.4252]])\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7426b6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear w:  Parameter containing:\n",
      "tensor([[ 0.2465,  0.2989,  0.1212],\n",
      "        [ 0.4536,  0.2229, -0.0767]], requires_grad=True)\n",
      "linear b:  Parameter containing:\n",
      "tensor([0.2326, 0.2448], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#Build fully connected layer\n",
    "linear = nn.Linear(3,2)\n",
    "print(\"linear w: \", linear.weight)\n",
    "print(\"linear b: \", linear.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb3846cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(linear.parameters(),lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d3de071",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5eb08676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2513, -0.0198],\n",
      "        [ 0.5715,  0.4050],\n",
      "        [ 0.0704,  0.1078],\n",
      "        [ 0.3354,  0.3355],\n",
      "        [ 0.1309, -0.1450],\n",
      "        [ 0.3388,  0.2359],\n",
      "        [-0.5300, -0.8524],\n",
      "        [ 0.3500,  0.2735],\n",
      "        [-0.3493,  0.0424],\n",
      "        [ 0.5963,  0.9027]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.1706,  1.2528],\n",
      "        [-0.1687,  0.0511],\n",
      "        [-1.6223,  0.5844],\n",
      "        [-0.8326,  1.3786],\n",
      "        [-0.0957, -0.6827],\n",
      "        [-0.9757, -0.0716],\n",
      "        [-1.7633, -1.2426],\n",
      "        [-0.0401, -0.7564],\n",
      "        [-1.7060, -1.7123],\n",
      "        [-0.3871, -0.8928]])\n"
     ]
    }
   ],
   "source": [
    "print(pred)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce99337f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  1.1001617908477783\n"
     ]
    }
   ],
   "source": [
    "loss = criterion(pred, y)\n",
    "print('loss: ', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0139d415",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff090cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dl/dw:  tensor([[-0.4084,  0.1667, -0.4986],\n",
      "        [ 0.2053, -0.2400, -0.2387]])\n"
     ]
    }
   ],
   "source": [
    "print(\"dl/dw: \", linear.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1515696f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dl/db:  tensor([0.9186, 0.3377])\n"
     ]
    }
   ],
   "source": [
    "print(\"dl/db: \", linear.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b3c2804",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1acb6154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss after 1 step optimization:  1.0846866369247437\n"
     ]
    }
   ],
   "source": [
    "pred = linear(x)\n",
    "loss = criterion(pred, y)\n",
    "print('loss after 1 step optimization: ', loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a6a9435",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e04274d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09d57b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss after 2 step optimization:  1.0545474290847778\n"
     ]
    }
   ],
   "source": [
    "pred = linear(x)\n",
    "loss = criterion(pred, y)\n",
    "print('loss after 2 step optimization: ', loss.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ba8051",
   "metadata": {},
   "source": [
    "Loading data from numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3fd90108",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1,2],[3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3b6e4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.from_numpy(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d654eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ab72b4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "z = y.numpy()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5c2ac6",
   "metadata": {},
   "source": [
    "Input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ec6976ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../../data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bd20d6e8fd543e492c2f8de358c4b0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../data/cifar-10-python.tar.gz to ../../data/\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
    "                                             train=True, \n",
    "                                             transform=transforms.ToTensor(),\n",
    "                                             download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "31172a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "image, label = train_dataset[0]\n",
    "print (image.size())\n",
    "print (label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2d5743dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader (this provides queues and threads in a very simple way).\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=64, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e98b278e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When iteration starts, queue and thread start to load data from files.\n",
    "data_iter = iter(train_loader)\n",
    "\n",
    "# Mini-batch images and labels.\n",
    "images, labels = data_iter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34572d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual usage of the data loader is as below.\n",
    "for images, labels in train_loader:\n",
    "    # Training code should be written here.\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
